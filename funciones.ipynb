{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def PlayTimeGenre(genero: str):\n",
    "    try:\n",
    "        # Leemos el archivo parquet\n",
    "        df_genero = pd.read_parquet(\"Src/endpoint1.parquet\")\n",
    "        \n",
    "        # Filtrar el DataFrame por el género especificado\n",
    "        df_genero = df_genero[df_genero[\"genres\"] == genero]\n",
    "        \n",
    "        # Encontrar el año con más horas jugadas para el género\n",
    "        año_con_mas_horas = list(df_genero[df_genero[\"playtime\"] == df_genero[\"playtime\"].max()][\"release\"])[0]\n",
    "        \n",
    "        return {f\"Año de lanzamiento con más horas jugadas para {genero}\": año_con_mas_horas}\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Año de lanzamiento con más horas jugadas para Puzzle': 2009}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PlayTimeGenre('Puzzle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userforgenre(genero: str):\n",
    "    #Leemos el parquet\n",
    "    endpoint2 = pd.read_parquet('src/endpoint2.parquet')\n",
    "    \n",
    "    #Convertimos los minutos a horas\n",
    "    endpoint2['playtime'] = round(endpoint2['playtime']/60,2)\n",
    "    \n",
    "    #Filtramos el género solicitado\n",
    "    endpoint2_genero = endpoint2[endpoint2['genres'] == genero]\n",
    "    \n",
    "    #Buscamos el usuario con más horas en el género\n",
    "    usuario_con_mas_horas = endpoint2_genero.loc[endpoint2_genero['playtime'].idxmax()]['user_id']\n",
    "    \n",
    "    #Agrupamos por año \n",
    "    horas_por_año_usuario = endpoint2_genero[endpoint2_genero['user_id'] == usuario_con_mas_horas]\n",
    "    horas_por_año_usuario = horas_por_año_usuario.groupby('release')['playtime'].sum().reset_index()\n",
    "    horas_por_año_usuario = horas_por_año_usuario.rename(columns = {'release': 'Año','playtime':'Horas'})\n",
    "\n",
    "    #Creamos la listita de acumulacion de horas jugadas por año\n",
    "    lista_horas_por_año = horas_por_año_usuario.to_dict(orient='records')\n",
    "    return {f\"Usuario con más horas jugadas para {genero}\": usuario_con_mas_horas,\n",
    "        \"Horas jugadas\": lista_horas_por_año}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Usuario con más horas jugadas para Action': 'Evilutional',\n",
       " 'Horas jugadas': [{'Año': 2009, 'Horas': 33.95},\n",
       "  {'Año': 2010, 'Horas': 68.37},\n",
       "  {'Año': 2011, 'Horas': 32.8},\n",
       "  {'Año': 2012, 'Horas': 11349.85},\n",
       "  {'Año': 2013, 'Horas': 1162.1},\n",
       "  {'Año': 2014, 'Horas': 403.77},\n",
       "  {'Año': 2015, 'Horas': 1.87},\n",
       "  {'Año': 2016, 'Horas': 21.52},\n",
       "  {'Año': 2017, 'Horas': 181.57}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userforgenre('Action')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UsersRecommend(year: int):\n",
    "    try:\n",
    "        # Leemos el archivo\n",
    "        df = pd.read_parquet('src/reviews.parquet')\n",
    "        #print(\"DataFrame cargado:\", df.head())  # Verificamos los primeros registros del DataFrame\n",
    "        \n",
    "        # Filtramos por año\n",
    "        df_year = df[df['posted_year'] == year]\n",
    "        #print(\"Registros para el año\", year, \":\", len(df_year))  # Verificamos cuántos registros hay para el año específico\n",
    "        \n",
    "        # Filtramos por recomendaciones positivas/neutrales\n",
    "        df_recommend = df_year[df_year['recommend'] == True]\n",
    "        df_sentiment = df_recommend[df_recommend['sentiment_analysis'].isin([2, 1])]\n",
    "        #print(\"Registros con recomendaciones positivas/neutrales:\", len(df_sentiment))  # Verificamos cuántos registros cumplen con los criterios de recomendación y sentimiento\n",
    "        \n",
    "        # Excluimos títulos 'Otros'\n",
    "        df_filtered = df_sentiment[df_sentiment['title'] != 'Otros']\n",
    "        # print(\"Registros después de excluir 'Otros':\", len(df_filtered))  # Verificamos cuántos registros quedan después de excluir 'Otros'\n",
    "        \n",
    "        # Agrupamos por título y contamos las recomendaciones\n",
    "        recommendations = df_filtered.groupby('title')['recommend'].sum()\n",
    "        #print(\"Recomendaciones por juego:\", recommendations)  # Verificamos el conteo de recomendaciones por juego\n",
    "        \n",
    "        # Ordenamos las recomendaciones por número de recomendaciones \n",
    "        recommendations_sorted = recommendations.sort_values(ascending=False)\n",
    "        \n",
    "        # Tomamos los tres primeros juegos\n",
    "        top_3 = recommendations_sorted.head(3)\n",
    "        #print(\"Top 3 juegos recomendados:\", top_3)  # Verificamos el top 3 de juegos recomendados\n",
    "        \n",
    "        # Verificamos si hay suficientes juegos recomendados\n",
    "        if len(top_3) >= 3:\n",
    "            # Creamos una lista de diccionarios para los tres primeros juegos\n",
    "            result = [{\"Puesto {}\".format(i + 1): game} for i, game in enumerate(top_3.index)]\n",
    "        else:\n",
    "            # Si no hay suficientes juegos, devolvemos un mensaje de datos insuficientes\n",
    "            result = 'Datos insuficientes'\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Capturamos cualquier excepción y la devolvemos como un diccionario\n",
    "        return {\"error\": str(e)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Datos insuficientes'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UsersRecommend(2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UsersWorstDeveloper(year:int):\n",
    "    try:\n",
    "        # Leemos el archivo\n",
    "        df = pd.read_parquet('src/reviews.parquet')\n",
    "        #print(\"DataFrame cargado:\", df.head())  # Verificamos los primeros registros del DataFrame\n",
    "        \n",
    "        # Filtramos por año\n",
    "        df_year = df[df['posted_year'] == year]\n",
    "        #print(\"Registros para el año\", year, \":\", len(df_year))  # Verificamos cuántos registros hay para el año específico\n",
    "        \n",
    "        # Filtramos por recomendaciones positivas/neutrales\n",
    "        df_recommend = df_year[df_year['recommend'] == False]\n",
    "        df_sentiment = df_recommend[df_recommend['sentiment_analysis'] == 0]\n",
    "        #print(\"Registros con recomendaciones positivas/neutrales:\", len(df_sentiment))  # Verificamos cuántos registros cumplen con los criterios de recomendación y sentimiento\n",
    "        \n",
    "        # Excluimos títulos 'Otros'\n",
    "        df_filtered = df_sentiment[df_sentiment['developer'] != 'Otros']\n",
    "        # print(\"Registros después de excluir 'Otros':\", len(df_filtered))  # Verificamos cuántos registros quedan después de excluir 'Otros'\n",
    "        \n",
    "        # Agrupamos por título y contamos las recomendaciones\n",
    "        negative_recommendations = df_filtered.groupby('developer')['recommend'].sum()\n",
    "        #print(\"Recomendaciones por juego:\", recommendations)  # Verificamos el conteo de recomendaciones por juego\n",
    "        \n",
    "        # Ordenamos las recomendaciones por número de recomendaciones \n",
    "        negative_recommendations_sorted = negative_recommendations.sort_values(ascending=False)\n",
    "        \n",
    "        # Tomamos los tres primeros juegos\n",
    "        top_3 = negative_recommendations_sorted.head(3)\n",
    "        #print(\"Top 3 juegos recomendados:\", top_3)  # Verificamos el top 3 de juegos recomendados\n",
    "        \n",
    "        # Verificamos si hay suficientes juegos recomendados\n",
    "        if len(top_3) >= 3:\n",
    "            # Creamos una lista de diccionarios para los tres primeros juegos\n",
    "            result = [{\"Puesto {}\".format(i + 1): game} for i, game in enumerate(top_3.index)]\n",
    "        else:\n",
    "            # Si no hay suficientes juegos, devolvemos un mensaje de datos insuficientes\n",
    "            result = 'Datos insuficientes'\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Capturamos cualquier excepción y la devolvemos como un diccionario\n",
    "        return {\"error\": str(e)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Puesto 1': '10th Art Studio,Adventure Productions'},\n",
       " {'Puesto 2': 'Red Duck Inc.'},\n",
       " {'Puesto 3': 'Reality Pump'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UsersWorstDeveloper(2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentimentAnalysis(desarrolladora:str):\n",
    "    try:\n",
    "        #Leemos el archivo    \n",
    "        df_sentiment = pd.read_parquet('src/reviews.parquet')\n",
    "        \n",
    "        #Filtramos el df con la desarrolladora\n",
    "        df_developer = df_sentiment[df_sentiment['developer'] == desarrolladora]\n",
    "        \n",
    "        #Contabilizamos las reviews\n",
    "        positive_count = (df_developer['sentiment_analysis'] == 2).sum()\n",
    "        neutral_count = (df_developer['sentiment_analysis'] == 1).sum()\n",
    "        negative_count = (df_developer['sentiment_analysis'] == 0).sum()\n",
    "        \n",
    "        #Creamos el diccionario solicitado:\n",
    "        result_dicc = {\n",
    "            'Desarrolladora': desarrolladora,\n",
    "            'Reviews Positivas': positive_count,\n",
    "            'Reviews Neutras': neutral_count,\n",
    "            'Reviews Negativas': negative_count\n",
    "        }\n",
    "        return result_dicc\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Capturamos cualquier excepción y la devolvemos como un diccionario\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Desarrolladora': 'Ubisoft',\n",
       " 'Reviews Positivas': 83,\n",
       " 'Reviews Neutras': 1,\n",
       " 'Reviews Negativas': 35}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SentimentAnalysis('Ubisoft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recomendacion_juego(id: int):\n",
    "    # Leemos el dataset \n",
    "    games_ML = pd.read_parquet('src/games_ML.parquet')\n",
    "    # Verifica si el juego con game_id existe en df_games\n",
    "    game = games_ML[games_ML['id'] == id]\n",
    "\n",
    "    if game.empty:\n",
    "        return(\"El juego '{id}' no posee registros.\")\n",
    "    \n",
    "    # Obtiene el índice del juego dado\n",
    "    idx = game.index[0]\n",
    "\n",
    "    # Toma una muestra aleatoria del DataFrame df_games\n",
    "    sample_size = 2000  # Define el tamaño de la muestra (ajusta según sea necesario)\n",
    "    df_sample = games_ML.sample(n=sample_size, random_state=42)  # Ajusta la semilla aleatoria según sea necesario\n",
    "\n",
    "    # Calcula la similitud de contenido solo para el juego dado y la muestra\n",
    "    sim_scores = cosine_similarity([games_ML.iloc[idx, 3:]], df_sample.iloc[:, 3:])\n",
    "\n",
    "    # Obtiene las puntuaciones de similitud del juego dado con otros juegos\n",
    "    sim_scores = sim_scores[0]\n",
    "\n",
    "    # Ordena los juegos por similitud en orden descendente\n",
    "    similar_games = [(i, sim_scores[i]) for i in range(len(sim_scores)) if i != idx]\n",
    "    similar_games = sorted(similar_games, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Obtiene los 5 juegos más similares\n",
    "    similar_game_indices = [i[0] for i in similar_games[:5]]\n",
    "\n",
    "    # Lista de juegos similares (solo nombres)\n",
    "    similar_game_names = df_sample['title'].iloc[similar_game_indices].tolist()\n",
    "\n",
    "    return {f\"Juegos Similares\": similar_game_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrecomendacion_juego\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m, in \u001b[0;36mrecomendacion_juego\u001b[1;34m(id_producto)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecomendacion_juego\u001b[39m(id_producto: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Leemos el dataset \u001b[39;00m\n\u001b[0;32m      3\u001b[0m     games_ML \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc/games_ML.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     cosine_similarity\u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msrc/similitudes.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Verificamos si el juego con el id dado existe\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     game \u001b[38;5;241m=\u001b[39m games_ML[games_ML[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m id_producto]\n",
      "File \u001b[1;32md:\\Henry\\Carrera\\Proyecto Individual Final\\Proyecto_Individual_Final\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Henry\\Carrera\\Proyecto Individual Final\\Proyecto_Individual_Final\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:281\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    275\u001b[0m         path_or_handle,\n\u001b[0;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 281\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mto_pandas_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    284\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_as_manager(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Henry\\Carrera\\Proyecto Individual Final\\Proyecto_Individual_Final\\.venv\\Lib\\site-packages\\pyarrow\\array.pxi:883\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Henry\\Carrera\\Proyecto Individual Final\\Proyecto_Individual_Final\\.venv\\Lib\\site-packages\\pyarrow\\table.pxi:4251\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Henry\\Carrera\\Proyecto Individual Final\\Proyecto_Individual_Final\\.venv\\Lib\\site-packages\\pyarrow\\pandas_compat.py:777\u001b[0m, in \u001b[0;36mtable_to_dataframe\u001b[1;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[0;32m    775\u001b[0m _check_data_column_metadata_consistency(all_columns)\n\u001b[0;32m    776\u001b[0m columns \u001b[38;5;241m=\u001b[39m _deserialize_column_index(table, all_columns, column_indexes)\n\u001b[1;32m--> 777\u001b[0m blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_table_to_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mext_columns_dtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    780\u001b[0m mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes)\n",
      "File \u001b[1;32md:\\Henry\\Carrera\\Proyecto Individual Final\\Proyecto_Individual_Final\\.venv\\Lib\\site-packages\\pyarrow\\pandas_compat.py:1133\u001b[0m, in \u001b[0;36m_table_to_blocks\u001b[1;34m(options, block_table, categories, extension_columns)\u001b[0m\n\u001b[0;32m   1130\u001b[0m columns \u001b[38;5;241m=\u001b[39m block_table\u001b[38;5;241m.\u001b[39mcolumn_names\n\u001b[0;32m   1131\u001b[0m result \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mtable_to_blocks(options, block_table, categories,\n\u001b[0;32m   1132\u001b[0m                                 \u001b[38;5;28mlist\u001b[39m(extension_columns\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m-> 1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43m_reconstruct_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32md:\\Henry\\Carrera\\Proyecto Individual Final\\Proyecto_Individual_Final\\.venv\\Lib\\site-packages\\pyarrow\\pandas_compat.py:1133\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1130\u001b[0m columns \u001b[38;5;241m=\u001b[39m block_table\u001b[38;5;241m.\u001b[39mcolumn_names\n\u001b[0;32m   1131\u001b[0m result \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mtable_to_blocks(options, block_table, categories,\n\u001b[0;32m   1132\u001b[0m                                 \u001b[38;5;28mlist\u001b[39m(extension_columns\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m-> 1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43m_reconstruct_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[1;32md:\\Henry\\Carrera\\Proyecto Individual Final\\Proyecto_Individual_Final\\.venv\\Lib\\site-packages\\pyarrow\\pandas_compat.py:679\u001b[0m, in \u001b[0;36m_reconstruct_block\u001b[1;34m(item, columns, extension_columns)\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values, type_\n\u001b[0;32m    675\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;66;03m# Converting pyarrow.Table efficiently to pandas.DataFrame\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reconstruct_block\u001b[39m(item, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extension_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    680\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;124;03m    Construct a pandas Block from the `item` dictionary coming from pyarrow's\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;124;03m    serialization or returned by arrow::python::ConvertTableToPandas.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    705\u001b[0m \n\u001b[0;32m    706\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_int\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recomendacion_juego(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2885 entries, 0 to 2884\n",
      "Data columns (total 24 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   id                          2885 non-null   int64 \n",
      " 1   app_name                    2885 non-null   object\n",
      " 2   _Accounting                 2885 non-null   int64 \n",
      " 3   _Action                     2885 non-null   int64 \n",
      " 4   _Adventure                  2885 non-null   int64 \n",
      " 5   _Animation &amp; Modeling   2885 non-null   int64 \n",
      " 6   _Audio Production           2885 non-null   int64 \n",
      " 7   _Casual                     2885 non-null   int64 \n",
      " 8   _Design &amp; Illustration  2885 non-null   int64 \n",
      " 9   _Early Access               2885 non-null   int64 \n",
      " 10  _Education                  2885 non-null   int64 \n",
      " 11  _Free to Play               2885 non-null   int64 \n",
      " 12  _Indie                      2885 non-null   int64 \n",
      " 13  _Massively Multiplayer      2885 non-null   int64 \n",
      " 14  _Photo Editing              2885 non-null   int64 \n",
      " 15  _RPG                        2885 non-null   int64 \n",
      " 16  _Racing                     2885 non-null   int64 \n",
      " 17  _Simulation                 2885 non-null   int64 \n",
      " 18  _Software Training          2885 non-null   int64 \n",
      " 19  _Sports                     2885 non-null   int64 \n",
      " 20  _Strategy                   2885 non-null   int64 \n",
      " 21  _Utilities                  2885 non-null   int64 \n",
      " 22  _Video Production           2885 non-null   int64 \n",
      " 23  _Web Publishing             2885 non-null   int64 \n",
      "dtypes: int64(23), object(1)\n",
      "memory usage: 541.1+ KB\n"
     ]
    }
   ],
   "source": [
    "modelo_render = pd.read_parquet('src\\modelo_render.parquet')\n",
    "modelo_render.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
